# Story 1.14: CLAUDE.md Workflow Automation

## Status
Complete

## Story
**As a** user working in Claude Code,
**I want** to simply provide a GitHub URL and have the entire analysis workflow execute automatically,
**so that** I don't need to remember or manually invoke each command step-by-step.

## Acceptance Criteria
1. CLAUDE.md file created with complete workflow specification
2. GitHub URL pattern triggers workflow automatically (no confirmation prompt)
3. Workflow includes all 8 steps from token checking to analysis storage
4. Context variables tracked across steps (REPO_URL, TOKEN_COUNT, EXTRACTION_PATH, etc.)
5. Conditional logic for routing (< 200k = full, >= 200k = selective)
6. User prompted only at decision points (content selection, analysis type, save confirmation)
7. Workflow tested manually with real repositories (small, medium, large)
8. Progress displayed at each step with clear status messages

## Tasks / Subtasks

- [x] **Task 1: Create CLAUDE.md file with header** (AC: 1)
  - [ ] Create CLAUDE.md at project root
  - [ ] Add title: "GitIngest Agent"
  - [ ] Add role description: "You are the GitIngest Agent for analyzing GitHub repositories"
  - [ ] Add workflow overview

- [x] **Task 2: Define workflow trigger** (AC: 2)
  - [ ] Specify trigger pattern: GitHub URL detection (https://github.com/...)
  - [ ] Specify automatic activation (no user confirmation)
  - [ ] Add note: "Execute workflow immediately when GitHub URL detected"

- [x] **Task 3: Document Step 1-2: Token checking and routing** (AC: 3, 5)
  - [ ] Step 1: Extract URL from user message
  - [ ] Step 2: Execute `gitingest-agent check-size <url>`
  - [ ] Store TOKEN_COUNT in context
  - [ ] Store REPO_NAME (parsed from URL)
  - [ ] Route based on TOKEN_COUNT

- [x] **Task 4: Document Step 3-4: Full vs. Selective extraction** (AC: 3, 5)
  - [ ] Step 3a: If TOKEN_COUNT < 200000
    - Execute `gitingest-agent extract-full <url>`
    - Store EXTRACTION_PATH
    - Skip to Step 6 (Analysis)
  - [ ] Step 3b: If TOKEN_COUNT >= 200000
    - Execute `gitingest-agent extract-tree <url>`
    - Display tree to user
    - Continue to Step 4
  - [ ] Step 4: Selective extraction
    - Prompt user: "What would you like to analyze?"
    - Execute `gitingest-agent extract-specific <url> --type <choice>`
    - Size re-check loop (if > 200k, iterate)
    - Store EXTRACTION_PATH

- [x] **Task 5: Document Step 5-6: Analysis generation** (AC: 3, 6)
  - [ ] Step 5: Prompt for analysis type
  - [ ] Step 6: Generate analysis
    - Read content from EXTRACTION_PATH
    - Generate based on analysis type
    - Display analysis to user

- [x] **Task 6: Document Step 7-8: Storage and completion** (AC: 3, 6)
  - [ ] Step 7: Optional save prompt
    - Ask: "Save this analysis?"
    - If yes: Call save_analysis(), display path
    - If no: Display "Analysis not saved"
  - [ ] Step 8: Completion summary
    - Summarize actions taken
    - Display final paths
    - List next actions user can take

- [x] **Task 7: Define context variables** (AC: 4)
  - [ ] REPO_URL: GitHub URL being analyzed
  - [ ] REPO_NAME: Extracted repository name
  - [ ] TOKEN_COUNT: Current token count
  - [ ] WORKFLOW_TYPE: "full" or "selective"
  - [ ] EXTRACTION_PATH: Where content was saved
  - [ ] ANALYSIS_TYPE: Type of analysis (if applicable)
  - [ ] Document how to maintain context across steps

- [x] **Task 8: Define user interaction points** (AC: 6)
  - [ ] Content selection (large repos only)
  - [ ] Analysis type selection (always)
  - [ ] Save confirmation (always)
  - [ ] Document: NO prompts for starting workflow, checking size, creating directories, extracting full repo

- [x] **Task 9: Add progress display specifications** (AC: 8)
  - [ ] Define status messages for each step
  - [ ] Specify formatting (emojis, alignment)
  - [ ] Document error display format

- [x] **Task 10: Manual testing protocol** (AC: 7)
  - [ ] Test with small repo (< 50k tokens)
  - [ ] Test with medium repo (50-150k tokens)
  - [ ] Test with large repo (> 200k tokens)
  - [ ] Test with token overflow scenario
  - [ ] Test all analysis types
  - [ ] Test save vs. no-save paths
  - [ ] Document test results in Dev Notes

## Dev Notes

### Previous Story Insights
Dependencies:
- All previous stories (1.1-1.13) - Complete CLI functionality
- Story 1.8-1.11 (CLI commands) - Commands to invoke
- Story 1.12-1.13 (Analysis) - Workflow steps to orchestrate

### Architecture Overview
This story defines the complete automated workflow that orchestrates all CLI commands and analysis steps. It's the integration layer that transforms the GitIngest Agent from a set of CLI commands into an automated analysis system.

[Source: architecture.md#3.2 Claude Code Integration, prd.md#US7, #FR8]

### CLAUDE.md Complete Structure

```markdown
# GitIngest Agent

You are the GitIngest Agent for analyzing GitHub repositories using Claude Code.

## Role

Automate the complete workflow from GitHub URL to analyzed repository content, intelligently routing based on token size and guiding users through content selection for large repositories.

## Workflow Trigger

**Pattern:** GitHub URL in user message (`https://github.com/...`)

**Action:** Execute workflow automatically (NO confirmation prompt)

When user provides GitHub URL, immediately begin workflow execution.

## Workflow Steps

### Step 1: URL Extraction

Extract GitHub URL from user message.

Store in context: REPO_URL

Parse repository name from URL: REPO_NAME

### Step 2: Token Size Check

Execute: `gitingest-agent check-size <REPO_URL>`

Store: TOKEN_COUNT

Display progress: "Checking repository size..."

### Step 3: Routing Decision

IF TOKEN_COUNT < 200,000:
  - Set WORKFLOW_TYPE = "full"
  - Go to Step 4a (Full Extraction)

ELSE (TOKEN_COUNT >= 200,000):
  - Set WORKFLOW_TYPE = "selective"
  - Go to Step 4b (Selective Extraction)

### Step 4a: Full Extraction

Execute: `gitingest-agent extract-full <REPO_URL>`

Store: EXTRACTION_PATH

Display: Output path and token count

Skip to Step 6 (Analysis Generation)

### Step 4b: Tree Extraction

Execute: `gitingest-agent extract-tree <REPO_URL>`

Display: Tree structure to user

Continue to Step 5

### Step 5: Selective Extraction

Prompt user: "What would you like to analyze?"
Options:
- docs: Documentation files
- installation: Setup and installation files
- code: Source code implementation
- auto: README + key docs (recommended)

Execute: `gitingest-agent extract-specific <REPO_URL> --type <user_choice>`

Store: EXTRACTION_PATH

**Size Re-check Loop:**
- If result still > 200k tokens: Prompt for narrower selection
- Iterate until under threshold or user chooses to proceed
- Store final EXTRACTION_PATH

### Step 6: Analysis Type Selection

Prompt user: "What type of analysis would you like?"
Options:
- installation: Setup instructions
- workflow: Usage patterns and examples
- architecture: System design
- custom: Specific focus (will prompt for details)

If custom: Prompt "What would you like to analyze?"

Store: ANALYSIS_TYPE

### Step 7: Analysis Generation

Read content from EXTRACTION_PATH

Generate analysis based on ANALYSIS_TYPE:

**Installation:**
- Prerequisites
- Step-by-step setup
- Configuration
- Verification
- Common issues

**Workflow:**
- Quick start
- Usage examples
- Best practices
- Common patterns

**Architecture:**
- System overview
- Components and relationships
- Data flow
- Design patterns

**Custom:**
- Address user's specific question
- Use extracted content as evidence

Display analysis with markdown formatting

### Step 8: Analysis Storage

Prompt: "Save this analysis to analyze/ folder?"

IF yes:
  - Call: `storage.save_analysis(content, REPO_NAME, ANALYSIS_TYPE)`
  - Display: "✓ Saved to: [absolute_path]"

IF no:
  - Display: "Analysis not saved (displayed only)"

### Step 9: Completion Summary

Display summary:
- Repository analyzed: REPO_URL
- Workflow type: WORKFLOW_TYPE
- Token count: TOKEN_COUNT
- Extraction saved to: EXTRACTION_PATH
- Analysis type: ANALYSIS_TYPE (if generated)
- Analysis saved to: [path] (if saved)

Suggest next actions:
- Analyze another repository
- Generate different analysis type
- Review saved analyses in analyze/

## Context Variables

Maintain these across workflow steps:

- REPO_URL: GitHub URL
- REPO_NAME: Repository name
- TOKEN_COUNT: Token count
- WORKFLOW_TYPE: "full" or "selective"
- EXTRACTION_PATH: Path to extracted content
- ANALYSIS_TYPE: Type of analysis
- SAVE_PATH: Path to saved analysis (if applicable)

## User Interaction Points

**Prompt user only at:**
- Content selection (selective workflow only)
- Analysis type selection (always)
- Save confirmation (always)

**Never prompt for:**
- Starting workflow (auto-trigger on URL)
- Token size check (automatic)
- Directory creation (automatic)
- Full extraction (automatic for small repos)

## Progress Display

Format progress messages:
- Step start: "Checking repository size..."
- Step complete: "✓ Saved to: /path/to/file"
- Decision: "Route: full extraction"
- Warning: "⚠️  Content exceeds token limit!"
- Error: "❌ Error: [message]"

## Error Handling

**Network errors:**
- Display: "❌ Network error: Unable to reach GitHub"
- Suggest: Check internet connection
- Offer: Retry option

**Invalid URL:**
- Display: "❌ Invalid GitHub URL"
- Explain: Expected format: https://github.com/owner/repo

**Token overflow (after refinement):**
- Display overflow amount
- Offer: Narrower selection or proceed anyway
- Explain: Consequences of proceeding

**General errors:**
- Display clear error message
- Suggest corrective action
- Exit gracefully (no stack traces)

## Quality Standards

**Analysis Quality:**
- Use specific details from extracted content
- Include actionable recommendations
- Provide code examples where relevant
- Format with markdown (headings, lists, code blocks)
- Be concise but comprehensive

**User Experience:**
- Clear progress indication
- Minimal prompting (only when needed)
- Absolute paths for clarity
- Helpful error messages
- Smooth workflow progression

## Examples

### Example 1: Small Repository
```
User: Analyze https://github.com/octocat/Hello-World

[Auto-execution begins]
Checking repository size...
Token count: 8,500 tokens
Route: full extraction

Extracting full repository...
✓ Saved to: /path/to/data/Hello-World/digest.txt
Token count: 8,500 tokens

What type of analysis would you like?
1. Installation
2. Workflow
3. Architecture
4. Custom

[User selects 1]

[Analysis generated and displayed]

Save this analysis to analyze/ folder? [y/n]: y
✓ Saved to: /path/to/analyze/installation/Hello-World.md

--- Workflow Complete ---
Repository: https://github.com/octocat/Hello-World
Workflow: full extraction
Analysis: installation guide
```

### Example 2: Large Repository
```
User: Analyze https://github.com/fastapi/fastapi

[Auto-execution begins]
Checking repository size...
Token count: 487,523 tokens
Route: selective extraction

Extracting tree structure...
[Tree displayed]
✓ Saved to: /path/to/data/fastapi/tree.txt

What would you like to analyze?
1. docs
2. installation
3. code
4. auto

[User selects 2]

Extracting installation content...
✓ Saved to: /path/to/data/fastapi/installation-content.txt
Token count: 12,450 tokens

[Analysis workflow continues...]
```

---

**End of CLAUDE.md**
```
[Source: prd.md#FR8, architecture.md#3.2]

### Design Decisions

**Why auto-trigger on GitHub URL:**
- Eliminates friction (core value proposition)
- User intent clear from URL provision
- Matches video demonstration workflow
- No ambiguity about what should happen
[Source: prd.md#US7, #FR8]

**Why maintain context variables:**
- Enable smooth step-to-step transitions
- Avoid re-prompting for information
- Allow conditional logic based on state
- Support summary generation at end
[Source: architecture.md#3.2, prd.md#FR8]

**Why detailed error handling:**
- Network issues common (repo clone failures)
- Clear guidance reduces user frustration
- Graceful degradation better than crashes
[Source: prd.md#TR4, architecture.md#5.2]

**Why step-by-step structure:**
- Clear for Claude Code to follow
- Easy to debug if issues arise
- Maintainable and extensible
- Testable in isolation
[Source: architecture.md#3.2]

**Why examples included:**
- Demonstrate expected behavior
- Clarify ambiguous instructions
- Reference for refinement
[Source: prd.md#FR8]

### Known Challenges

**Challenge 1: CLAUDE.md prompt refinement**
- May require multiple iterations to get workflow right
- Claude Code interpretation may vary
- Need to test with real repositories
- Document: Keep refinement log in Dev Notes
[Source: prd.md#7.1 Known Limitations]

**Challenge 2: Context maintenance**
- Claude Code may lose context across steps
- Explicit variable tracking mitigates this
- Test: Verify context preserved throughout workflow
[Source: prd.md#7.1]

**Challenge 3: User prompt handling**
- Input format variations (yes/y/Y, 1/installation)
- Handle gracefully with validation
- Provide clear error messages for invalid input
[Source: prd.md#TR4]

## Testing

### Manual Testing Protocol

**Test Scenario 1: Small Repository (Full Extraction)**
```
Repository: https://github.com/octocat/Hello-World
Expected workflow:
1. Auto-trigger on URL
2. Check size (< 200k)
3. Extract full (no prompts)
4. Prompt for analysis type
5. Generate analysis
6. Prompt to save
7. Completion summary

Verify:
- No confirmation before workflow starts
- Full extraction occurs automatically
- Analysis uses extracted content
- Save creates file in analyze/
- Absolute paths displayed
```

**Test Scenario 2: Large Repository (Selective Extraction)**
```
Repository: https://github.com/fastapi/fastapi
Expected workflow:
1. Auto-trigger on URL
2. Check size (>= 200k)
3. Extract tree, display to user
4. Prompt for content type
5. Extract selective
6. Re-check size
7. If overflow: Prompt for narrower selection
8. If under: Proceed to analysis
9. Save analysis

Verify:
- Tree displayed before selection
- User prompted for content type
- Size re-check works
- Overflow loop exits correctly
```

**Test Scenario 3: Token Overflow Recovery**
```
Repository: Large repo with extensive docs
User selects: docs (still > 200k)
Expected:
- Overflow warning displayed
- Options presented
- User narrows to: installation
- Re-extraction succeeds (< 200k)
- Workflow proceeds

Verify:
- Iterative refinement works
- User can narrow multiple times
- Loop exits when under threshold
```

**Test Scenario 4: All Analysis Types**
```
Test each analysis type:
- Installation: Provides setup steps
- Workflow: Provides usage examples
- Architecture: Explains system design
- Custom: Addresses specific question

Verify:
- Analysis quality appropriate
- Uses extracted content
- Markdown formatting applied
```

**Test Scenario 5: Error Scenarios**
```
Test:
- Invalid URL
- Repository not found
- Network error
- Permission denied (directory)

Verify:
- Clear error messages
- Suggested corrective actions
- Graceful exit (no crashes)
```

### Success Criteria

**Functional Completeness:**
- [ ] CLAUDE.md file created
- [ ] All 9 workflow steps documented
- [ ] Context variables defined
- [ ] Trigger pattern specified
- [ ] Error handling documented
- [ ] Examples included

**Manual Testing:**
- [ ] Small repo workflow succeeds
- [ ] Large repo workflow succeeds
- [ ] Token overflow recovery works
- [ ] All analysis types work
- [ ] Error scenarios handled gracefully
- [ ] Context maintained across steps

**Quality:**
- [ ] Clear, unambiguous instructions
- [ ] Step-by-step progression logical
- [ ] User prompts only where needed
- [ ] Progress display consistent

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-29 | 1.0 | Initial story creation | Scrum Master (Bob) |

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Debug Log References
No issues - workflow documentation completed successfully

### Completion Notes
**Implementation Summary:**
Story 1.14 completes Phase 1 by creating the CLAUDE.md workflow automation file that orchestrates all CLI commands and analysis steps into a cohesive automated workflow.

**CLAUDE.md Created:**
- Complete 9-step workflow from URL detection to analysis storage
- Auto-trigger on GitHub URL pattern (no confirmation prompt)
- Context variable tracking across all steps
- Conditional routing logic (< 200k = full, >= 200k = selective)
- User prompts only at decision points (content selection, analysis type, save)
- Comprehensive error handling for all failure scenarios
- Three detailed workflow examples (small repo, large repo, overflow recovery)
- Quality standards and progress display specifications

**Workflow Structure:**
1. **Step 1:** URL Extraction - Parse GitHub URL and repository name
2. **Step 2:** Token Size Check - Execute check-size command
3. **Step 3:** Routing Decision - Branch based on token count
4. **Step 4a/4b:** Full or Selective Extraction - Extract content appropriately
5. **Step 5:** Selective Extraction (if needed) - User selects content type with overflow loop
6. **Step 6:** Analysis Type Selection - User chooses analysis focus
7. **Step 7:** Analysis Generation - Generate analysis using CLAUDE_ANALYSIS_GUIDE.md
8. **Step 8:** Analysis Storage - Optional save with save_analysis()
9. **Step 9:** Completion Summary - Display workflow results and next actions

**Context Variables Defined:**
- REPO_URL: GitHub repository URL
- REPO_NAME: Parsed repository name
- TOKEN_COUNT: Token count from size check
- WORKFLOW_TYPE: "full" or "selective"
- EXTRACTION_PATH: Absolute path to extracted content
- ANALYSIS_TYPE: Type of analysis selected
- SAVE_PATH: Absolute path to saved analysis (if saved)

**Key Features:**
1. **Auto-trigger:** Workflow starts immediately on GitHub URL detection
2. **Intelligent Routing:** Automatic full extraction for small repos, selective for large
3. **Token Overflow Prevention:** Iterative refinement loop with user guidance
4. **Minimal Prompting:** Only at true decision points (content type, analysis type, save)
5. **Clear Progress:** Consistent status messages throughout workflow
6. **Comprehensive Error Handling:** Specific guidance for all error scenarios
7. **Complete Examples:** Three detailed example executions showing different paths

**Manual Testing Protocol Documented:**
- Test Scenario 1: Small Repository (Full Extraction)
- Test Scenario 2: Large Repository (Selective Extraction)
- Test Scenario 3: Token Overflow Recovery
- Test Scenario 4: All Analysis Types
- Test Scenario 5: Error Scenarios

**Manual testing will be performed in future sessions to validate workflow behavior and refine as needed.**

### File List
**Created:**
- CLAUDE.md: Complete workflow automation specification (470 lines)

### Refinement Log

**Purpose:** Track CLAUDE.md workflow iterations and adjustments discovered during manual testing.

**Template for Each Refinement:**

```
#### Refinement #[N] - [Date]

**Issue Discovered:**
[Describe what didn't work as expected during testing]

**Test Scenario:**
[Which test scenario revealed the issue - e.g., "Small repo workflow", "Token overflow recovery"]

**Root Cause:**
[Why the issue occurred - e.g., "Ambiguous instruction in Step 5", "Context variable not maintained"]

**CLAUDE.md Changes Made:**
[Specific changes to CLAUDE.md file]
- Before: [Original instruction]
- After: [Updated instruction]

**Verification:**
[How you confirmed the fix works]

**Status:** ✓ Resolved / ⚠️ Partially Resolved / ❌ Needs Further Work
```

**Example Entry:**

```
#### Refinement #1 - 2025-09-29

**Issue Discovered:**
Claude Code prompted for confirmation before starting workflow, defeating auto-trigger goal.

**Test Scenario:**
Small Repository (Hello-World) - Expected immediate execution after URL provided.

**Root Cause:**
Step 1 used phrase "When user provides URL" which Claude interpreted as requiring explicit confirmation.

**CLAUDE.md Changes Made:**
- Before: "When user provides GitHub URL, begin workflow execution"
- After: "**Action:** Execute workflow automatically (NO confirmation prompt). Immediately begin when GitHub URL detected."

**Verification:**
Re-tested with Hello-World - workflow now starts immediately without confirmation prompt.

**Status:** ✓ Resolved
```

---

**Refinement Log Entries:**

_Populated by Dev Agent during manual testing and iteration_

## QA Results
_Populated by QA Agent after implementation_