# Story 1.7: Extractor Module - Selective Extraction

## Status
Draft

## Story
**As a** developer implementing selective extraction workflows,
**I want** extractor functions for tree structure and filtered content extraction,
**so that** I can extract targeted repository sections for large repositories that exceed the token threshold.

## Acceptance Criteria
1. extract_tree() extracts minimal tree structure to data/[repo-name]/tree.txt
2. extract_specific() extracts filtered content based on content type
3. Filtered extraction uses workflow.get_filters_for_type() for filter patterns
4. Tree extraction displays structure to user (via return value)
5. Selective extraction saves to data/[repo-name]/[type]-content.txt
6. Both functions reuse _run_gitingest() helper for execution
7. Unit tests cover tree and selective extraction with various content types

## Tasks / Subtasks

- [ ] **Task 1: Implement extract_tree() function** (AC: 1, 4, 6)
  - [ ] Accept url parameter (GitHub URL)
  - [ ] Accept repo_name parameter (repository name for storage)
  - [ ] Call storage.ensure_data_directory(repo_name)
  - [ ] Define output_file: data_dir / "tree.txt"
  - [ ] Build GitIngest args for minimal extraction (structure only)
  - [ ] Use GitIngest filtering to minimize content: ['-i', 'README.md', '-s', '1024']
  - [ ] Call _run_gitingest() with arguments
  - [ ] Read tree content from file
  - [ ] Return tuple: (absolute_path, tree_content)

- [ ] **Task 2: Implement extract_specific() function** (AC: 2, 3, 5, 6)
  - [ ] Accept url parameter (GitHub URL)
  - [ ] Accept repo_name parameter (repository name)
  - [ ] Accept content_type parameter (docs, installation, code, auto)
  - [ ] Call workflow.get_filters_for_type(content_type) to get filter patterns
  - [ ] Call storage.ensure_data_directory(repo_name)
  - [ ] Define output_file: data_dir / f"{content_type}-content.txt"
  - [ ] Build GitIngest args with include/exclude patterns
  - [ ] Call _run_gitingest() with arguments
  - [ ] Return absolute path to output file

- [ ] **Task 3: Write unit tests for selective extraction** (AC: 7)
  - [ ] Test extract_tree() creates tree.txt file
  - [ ] Test extract_tree() returns path and content tuple
  - [ ] Test extract_specific() with 'docs' content type
  - [ ] Test extract_specific() with 'installation' content type
  - [ ] Test extract_specific() with 'code' content type
  - [ ] Test extract_specific() with 'auto' content type
  - [ ] Test extract_specific() file naming convention
  - [ ] Test extract_specific() calls get_filters_for_type()
  - [ ] Mock _run_gitingest() to avoid real GitIngest calls
  - [ ] Use pytest.tmp_path for filesystem isolation

## Dev Notes

### Previous Story Insights
Dependencies:
- Story 1.2 (exceptions) - Uses GitIngestError, StorageError
- Story 1.3 (storage) - Uses ensure_data_directory()
- Story 1.4 (workflow) - Uses get_filters_for_type()
- Story 1.6 (extractor) - Reuses _run_gitingest() helper

### Architecture Overview
This story completes the extractor module by implementing selective extraction for large repositories. Tree extraction provides repository structure overview, while specific extraction applies content filters to reduce token count.

[Source: architecture.md#2.4 Extractor Module, prd.md#FR3]

### Module Functions

**extract_tree(url: str, repo_name: str) -> tuple[str, str]**
```python
def extract_tree(url: str, repo_name: str) -> tuple[str, str]:
    """
    Extract minimal tree structure.

    Args:
        url: GitHub repository URL
        repo_name: Repository name for storage

    Returns:
        Tuple of (absolute_path, tree_content)

    Raises:
        GitIngestError: If extraction fails
        StorageError: If directory creation fails

    Examples:
        >>> path, tree = extract_tree("https://github.com/user/repo", "repo")
        >>> print(tree)
        README.md
        src/
          main.py
          utils.py
        docs/
          installation.md
    """
```
[Source: architecture.md#2.4, prd.md#FR3]

**Implementation Strategy:**
```python
def extract_tree(url: str, repo_name: str) -> tuple[str, str]:
    # Ensure directory exists
    data_dir = ensure_data_directory(repo_name)
    output_file = data_dir / "tree.txt"

    # Strategy: Extract with severe filtering to get structure only
    # -i README.md: Include at least one file (GitIngest requires content)
    # -s 1024: Maximum 1KB per file (forces truncation, shows structure)
    args = [
        url,
        '-i', 'README.md',
        '-s', '1024',
        '-o', str(output_file)
    ]

    _run_gitingest(args, timeout=120)

    # Read tree content to return for display
    tree_content = output_file.read_text(encoding='utf-8')

    return str(output_file.resolve()), tree_content
```
[Source: architecture.md#2.4]

**extract_specific(url: str, repo_name: str, content_type: str) -> str**
```python
def extract_specific(url: str, repo_name: str, content_type: str) -> str:
    """
    Extract targeted content with filtering.

    Args:
        url: GitHub repository URL
        repo_name: Repository name for storage
        content_type: Type of content (docs, installation, code, auto)

    Returns:
        Absolute path to [type]-content.txt file

    Raises:
        GitIngestError: If extraction fails
        StorageError: If directory creation fails
        ValidationError: If content_type is invalid

    Examples:
        >>> extract_specific("https://github.com/user/repo", "repo", "docs")
        '/path/to/data/repo/docs-content.txt'
    """
```
[Source: architecture.md#2.4, prd.md#FR3]

**Implementation Strategy:**
```python
def extract_specific(url: str, repo_name: str, content_type: str) -> str:
    # Get filter patterns from workflow module
    filters = get_filters_for_type(content_type)

    # Ensure directory exists
    data_dir = ensure_data_directory(repo_name)
    output_file = data_dir / f"{content_type}-content.txt"

    # Build GitIngest args with include/exclude patterns
    args = [url]

    # Add include patterns
    for pattern in filters['include']:
        args.extend(['-i', pattern])

    # Add exclude patterns
    for pattern in filters['exclude']:
        args.extend(['-e', pattern])

    # Add output file
    args.extend(['-o', str(output_file)])

    _run_gitingest(args, timeout=300)

    return str(output_file.resolve())
```
[Source: architecture.md#2.4, prd.md#FR4]

### Design Decisions

**Why extract_tree() returns tuple:**
- Path returned for confirmation message (CLI layer)
- Tree content returned for display to user
- User sees structure immediately without reading file
- Avoids duplicate file I/O in CLI layer
[Source: architecture.md#2.4, prd.md#FR3]

**Why tree extraction uses minimal filtering:**
- GitIngest requires some content to generate tree
- README.md is safe bet (most repos have it)
- 1KB file size limit forces truncation
- Results in structure-only output (file paths visible, minimal content)
[Source: architecture.md#2.4]

**Alternative tree extraction approach:**
Could use `git ls-tree` directly, but:
- Requires separate git implementation
- Inconsistent with GitIngest-based workflow
- GitIngest filtering simpler and adequate
[Source: architecture.md#2.4]

**Why content-type-based file naming:**
- Multiple selective extractions per repository
- Clear differentiation: docs-content.txt, installation-content.txt, code-content.txt
- User can compare different extractions
- All extractions preserved for future reference
[Source: prd.md#FR7, architecture.md#4.1]

**Filter pattern application:**
```bash
# Example: docs content type
gitingest https://github.com/user/repo \
  -i 'docs/**/*' \
  -i '*.md' \
  -i 'README*' \
  -i '*.rst' \
  -e 'docs/examples/*' \
  -e 'docs/archive/*' \
  -o data/repo/docs-content.txt
```
[Source: prd.md#FR4, architecture.md#2.4]

### File Location

**Modified in this story:**
- `extractor.py` (add extract_tree and extract_specific functions)

**Test file:**
- `tests/test_extractor.py` (add tests for new functions)

[Source: architecture.md#TR3 Project Structure]

### Storage Schema

**Files Created by This Story:**
```
data/
  {repo_name}/
    digest.txt                # Full extraction (Story 1.6)
    tree.txt                  # Tree structure (this story)
    docs-content.txt          # Selective: docs (this story)
    installation-content.txt  # Selective: installation (this story)
    code-content.txt          # Selective: code (this story)
```
[Source: prd.md#FR7, architecture.md#4.1]

### Workflow Integration

**Tree Extraction Workflow:**
```
User provides URL
  ↓
Token count ≥ 200,000
  ↓
extract_tree(url, repo_name) called
  ↓
Tree saved to data/repo/tree.txt
  ↓
Tree displayed to user (from return value)
  ↓
User selects content type
```
[Source: prd.md#FR3, architecture.md#1.2]

**Selective Extraction Workflow:**
```
User selects content type: "docs"
  ↓
CLI calls extract_specific(url, repo, "docs")
  ↓
workflow.get_filters_for_type("docs") returns patterns
  ↓
GitIngest executed with include/exclude filters
  ↓
Content saved to data/repo/docs-content.txt
  ↓
Path returned and displayed
  ↓
Token re-check (Story 1.11)
```
[Source: prd.md#FR3, #FR4, architecture.md#1.2]

### Performance Considerations

**Tree Extraction Time:**
- Faster than full extraction (minimal content)
- Typically < 30 seconds for any repo size
- Network bound (clone time only)
[Source: architecture.md#7.1]

**Selective Extraction Time:**
- Depends on filter scope
- Documentation: Usually < 90 seconds
- Installation files: Usually < 30 seconds
- Code (src/**/*.py): Varies widely
[Source: prd.md#6.4 Performance Benchmarks]

## Testing

### Testing Standards

**Test File Location:**
- `tests/test_extractor.py` (extend existing file from Story 1.6)

**Testing Framework:**
- pytest framework
- unittest.mock.patch for subprocess and workflow mocking
- pytest.tmp_path fixture for filesystem isolation

**Test Coverage:**
```python
@patch('extractor._run_gitingest')
@patch('storage.ensure_data_directory')
def test_extract_tree_success(mock_ensure_dir, mock_run, tmp_path):
    """Test successful tree extraction."""
    data_dir = tmp_path / "data" / "test-repo"
    data_dir.mkdir(parents=True)
    mock_ensure_dir.return_value = data_dir

    tree_file = data_dir / "tree.txt"
    tree_file.write_text("README.md\nsrc/\n  main.py\n")

    path, tree_content = extract_tree("https://github.com/user/repo", "test-repo")

    assert "tree.txt" in path
    assert "README.md" in tree_content
    assert "main.py" in tree_content

@patch('extractor._run_gitingest')
@patch('storage.ensure_data_directory')
def test_extract_tree_returns_tuple(mock_ensure_dir, mock_run, tmp_path):
    """Test extract_tree returns (path, content) tuple."""
    data_dir = tmp_path / "data" / "test-repo"
    data_dir.mkdir(parents=True)
    mock_ensure_dir.return_value = data_dir

    tree_file = data_dir / "tree.txt"
    tree_file.write_text("Tree content")

    result = extract_tree("https://github.com/user/repo", "test-repo")

    assert isinstance(result, tuple)
    assert len(result) == 2

@patch('extractor._run_gitingest')
@patch('workflow.get_filters_for_type')
@patch('storage.ensure_data_directory')
def test_extract_specific_docs(mock_ensure_dir, mock_filters, mock_run, tmp_path):
    """Test selective extraction with docs content type."""
    mock_filters.return_value = {
        'include': ['docs/**/*', '*.md'],
        'exclude': ['docs/examples/*']
    }
    data_dir = tmp_path / "data" / "test-repo"
    data_dir.mkdir(parents=True)
    mock_ensure_dir.return_value = data_dir

    output_path = extract_specific("https://github.com/user/repo", "test-repo", "docs")

    assert "docs-content.txt" in output_path
    mock_filters.assert_called_once_with("docs")

@patch('extractor._run_gitingest')
@patch('workflow.get_filters_for_type')
@patch('storage.ensure_data_directory')
def test_extract_specific_installation(mock_ensure_dir, mock_filters, mock_run, tmp_path):
    """Test selective extraction with installation content type."""
    mock_filters.return_value = {
        'include': ['README*', 'setup.py', 'pyproject.toml'],
        'exclude': []
    }
    data_dir = tmp_path / "data" / "test-repo"
    data_dir.mkdir(parents=True)
    mock_ensure_dir.return_value = data_dir

    output_path = extract_specific("https://github.com/user/repo", "test-repo", "installation")

    assert "installation-content.txt" in output_path
    mock_filters.assert_called_once_with("installation")

@patch('extractor._run_gitingest')
@patch('workflow.get_filters_for_type')
@patch('storage.ensure_data_directory')
def test_extract_specific_code(mock_ensure_dir, mock_filters, mock_run, tmp_path):
    """Test selective extraction with code content type."""
    mock_filters.return_value = {
        'include': ['src/**/*.py', 'lib/**/*.py'],
        'exclude': ['tests/*', 'test_*.py']
    }
    data_dir = tmp_path / "data" / "test-repo"
    data_dir.mkdir(parents=True)
    mock_ensure_dir.return_value = data_dir

    output_path = extract_specific("https://github.com/user/repo", "test-repo", "code")

    assert "code-content.txt" in output_path
    mock_filters.assert_called_once_with("code")

@patch('extractor._run_gitingest')
@patch('workflow.get_filters_for_type')
@patch('storage.ensure_data_directory')
def test_extract_specific_auto(mock_ensure_dir, mock_filters, mock_run, tmp_path):
    """Test selective extraction with auto content type."""
    mock_filters.return_value = {
        'include': ['README*', 'docs/**/*.md'],
        'exclude': ['docs/examples/*']
    }
    data_dir = tmp_path / "data" / "test-repo"
    data_dir.mkdir(parents=True)
    mock_ensure_dir.return_value = data_dir

    output_path = extract_specific("https://github.com/user/repo", "test-repo", "auto")

    assert "auto-content.txt" in output_path

@patch('extractor._run_gitingest')
@patch('workflow.get_filters_for_type')
@patch('storage.ensure_data_directory')
def test_extract_specific_builds_correct_args(mock_ensure_dir, mock_filters, mock_run, tmp_path):
    """Test GitIngest args include correct filter patterns."""
    mock_filters.return_value = {
        'include': ['*.md', 'docs/**/*'],
        'exclude': ['docs/archive/*']
    }
    data_dir = tmp_path / "data" / "test-repo"
    data_dir.mkdir(parents=True)
    mock_ensure_dir.return_value = data_dir

    extract_specific("https://github.com/user/repo", "test-repo", "docs")

    # Verify _run_gitingest called with correct args
    call_args = mock_run.call_args[0][0]
    assert '-i' in call_args
    assert '*.md' in call_args
    assert 'docs/**/*' in call_args
    assert '-e' in call_args
    assert 'docs/archive/*' in call_args
```

**Coverage Target:** 90%+ (critical path for large repository workflow)

### Success Criteria

**Functional Completeness:**
- [ ] extract_tree() function implemented
- [ ] extract_specific() function implemented
- [ ] Tree extraction creates tree.txt file
- [ ] Selective extraction uses content type filters
- [ ] File naming convention correct ([type]-content.txt)
- [ ] Both functions reuse _run_gitingest() helper
- [ ] All tests pass

**Code Quality:**
- [ ] Clear integration with workflow module (filters)
- [ ] Clear integration with storage module (paths)
- [ ] Type hints complete
- [ ] Docstrings with examples
- [ ] Error handling comprehensive

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-29 | 1.0 | Initial story creation | Scrum Master (Bob) |

## Dev Agent Record

### Agent Model Used
_Populated by Dev Agent during implementation_

### Debug Log References
_Populated by Dev Agent during implementation_

### Completion Notes
_Populated by Dev Agent during implementation_

### File List
_Populated by Dev Agent during implementation_

## QA Results
_Populated by QA Agent after implementation_